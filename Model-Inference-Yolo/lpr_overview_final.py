# -*- coding: utf-8 -*-
"""LPR_Overview_Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V5mQiN0DFwUwuk-QKUW_6vxDQwFaEjBS

# <font color='red' size='5px'/> LPR Project<font/>
"""

from IPython.display import Image

"""#<font color='blue' size='5px'/> Overview<font/>

## 1 Problem Statement

**Problem Statement:**

Design and implement a real-time license plate detection system capable of accurately detecting and localizing license plates in images. The system should be able to handle various environmental conditions, such as different lighting conditions, vehicle orientations, and background clutter, and provide reliable results for further processing or use in applications like traffic monitoring, parking management, or law enforcement.

## 2 Project Goal

**Key Objectives and Requirements:**
1. Develop or adopt a deep learning-based object detection model, such as YOLO, to detect license plates within a given image or video frame.
2. Annotate and curate a dataset of images containing vehicles with license plates, including various scenarios and license plate types.
3. Train the detection model on the dataset to achieve high accuracy and robustness in real-world conditions.
4. Implement post-processing techniques, like Non-Maximum Suppression (NMS), to refine the detected license plate bounding boxes.

6. Provide visual feedback by overlaying bounding boxes and text labels (license plate numbers) on detected license plates.
7. Develop a user-friendly interface for testing the system on live camera feeds and pre-recorded video.
8. Evaluate the system's performance using relevant metrics (e.g., precision, recall, F1-score) and ensure it meets or exceeds predefined accuracy targets.

10. Document the system's architecture, training process, and deployment instructions for future maintenance and scalability.


**Deliverables:**
- Trained license plate detection model.
- Software application or library for license plate detection with a user interface.
- Documentation detailing system architecture, data preparation, model training, and deployment instructions.
- Performance evaluation report, including accuracy metrics and real-time frame rates.

# <font color='blue' size='5px'/> Literature Review<font/>

## 1 Introduction

**Introduction**

The video is about using YOLO for drowsiness detection, including leveraging the ultralytics of YOLO, fine-tuning the drowsiness model, and testing it in real-time. The presenter showcases the implementation of the YOLO model and performs real-time detections using images, videos, and a webcam. Additionally, the video covers training a custom model for drowsiness detection.

**Loading Pre-Trained Ultralytics Model**

To load the pre-trained ultralytics model, we need to import torch, matplotlib, numpy and cv2 libraries. The model detects 38 cars and 4 trucks with reasonable confidence intervals in a new image passed through a new link.

**Real-Time Detection**

The speaker demonstrates real-time detection using YOLO on a video and a webcam. The code is creating a full file path to the image with a unique identifier and .jpg file extension. The presenter also shows how to run YOLO on a video file.

**Training Custom Drowsiness Detector Model**

The speaker closed the real-time detection and will now train a custom drowsiness detector model using collected images and labels. Two key dependencies need to be installed, piqt5 and lxml, followed by running pi rcc5 command to seed the label image file. The trainer explains the training command and its parameters for YOLOv5 object detection.

**Testing Custom Model**

The YOLO model has finished training and generated data, now it's time to test it. The presenter shows how to test the custom model on a new image, with the output showing whether the person in the image is alert or drowsy.

In summary, the video covers using YOLO for drowsiness detection, including loading pre-trained models, real-time detection on videos and webcams, training custom models, and testing them on new images.

[Original Video](https://www.youtube.com/watch?v=tFNJGim3FXw)

## 2 Dataset

#<font color='blue' size='5px'/> YOLOv5s Project<font/>

##  Packages
"""

import numpy as np
import cv2
import torch
from pathlib import Path
import matplotlib.pyplot as plt

from PIL import Image

import os

from google.colab import drive
drive.mount('/content/drive')

import torch
import torchvision
import torchvision.transforms as transforms ## For Transformation on Images
from torch.utils.data import DataLoader, Dataset

from torch.utils.data import  random_split

"""## Load Model"""

!pip install ultralytics

!git clone https://github.com/ultralytics/yolov5  # clone
!cd yolov5
!pip install -r requirements.txt  # install

"""The output shape of the model will be (batch_size, num_anchors, grid_size, grid_size, 5), where 5 refers to the number of predicted values for each anchor box, which includes the bounding box coordinates (x, y, width, height), and objectness score."""

# Model
model = torch.hub.load("ultralytics/yolov5", "yolov5s")  # or yolov5n - yolov5x6, custom

import torch
import utils
display = utils.notebook_init()  # checks

"""## Train Model

[Yolo-Doce-YML](https://docs.ultralytics.com/yolov5/tutorials/train_custom_data/#1-create-dataset)

[Yolo-PyTorch](https://pytorch.org/hub/ultralytics_yolov5/)
"""

!cd yolov5 && python train.py --img 512 --batch 16 --epochs 10 --data dataset.yml --weights yolov5s.pt --workers 2

from google.colab import files

# replace 'filename' with the name of the file that you want to download
files.download('/content/yolov5/runs')

from google.colab import files

# replace 'filename' with the name of the file that you want to download
files.download('/content/yolov5/runs/train/exp3')

"""## Import Weights"""

model = torch.hub.load('ultralytics/yolov5', 'custom', path='yolov5/runs/train/exp15/weights/last.pt', force_reload=True)